{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"julia-1.0","display_name":"Julia 1.0"},"accelerator":"GPU","colab":{"name":"16.01 – Convolutional neural networks","provenance":[{"file_id":"1QEyJVaLQJi1lrhd3MrS3j_I2j2v8CLuR","timestamp":1599156773921},{"file_id":"1PtxJeS3_CmX2xSZpmwhtYNlFQVfwk9vM","timestamp":1574769624475},{"file_id":"1oMPEqUhIyCphVCexXbkauuytJWI2GdlA","timestamp":1574289127295},{"file_id":"1bCs7QhD_ZwswH-dMbVoJHb5WbDdfhi_X","timestamp":1573572226314},{"file_id":"10n2JYjUZPo_WQPNDCf6LkCsTeXIHhjg9","timestamp":1573560458651},{"file_id":"1SvBM6AiSQ-TxddhLnaF0mcUYdtvJUXAp","timestamp":1573463816210},{"file_id":"1dvrhWR_ObIYVs9pxlXW-jGBRGVp2tQX1","timestamp":1572543467412},{"file_id":"1W_y94cY787aFyfugf7Nmty6Tm_3JrN66","timestamp":1571838794136},{"file_id":"1gMhnrMNP-het4rexXLXHzaOytfDpUxgR","timestamp":1571838737616}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"LHnPPzErnrr4","colab_type":"text"},"source":["## Housekeeping ##\n","\n","### About the tutorial yesterday… ###\n","\n","Teaching assistant did not confirm the location in the timetable, ended up going to the wrong place, then finally arrived at Gustave Tuck LT about 30 minutes late when all students obviously had given up on waiting. I found out at about the time when he arrived, my sincere apologies for this. We will go through the \n","\n","### Assignment 2 ###\n","\n","Some questions I have received so far:\n","\n","1. Yes, you are allowed to use any code you find online as long as you provide appropriate attribution – this does not mean you can directly share code between groups though, but drawing upon the same public code is fine.\n","\n","2. Yes, you can use any library or framework than you can get running on Colaboratory. I still advice against Keras as you are bound to soon outgrow it and struggle with its limitations. Personally, I am yet to find a single Keras user that did not migrate after a few months. Like most frameworks, it is wonderful as long as you are doing exactly the same thing that others have already done, but the moment you want something the authors could not concieve you are in a world of hurt.\n","\n","3. No, you are not expected to implement gridsearch again to explore different variants for Assignment 2. You should be familiar with the issues with gridsearch from Assignment 1. What you are expected to do is experiment with different variants, find out what works, describe the process, and only leave the final implementation in the Colaboratory notebook.\n","\n","Now, let us go through it quickly and do ask questions throughout.\n","\n","### Assignment 3 ###\n","\n","I have posted a placeholder on Moodle with a deadline at 12:00 on January 17th 2020."]},{"cell_type":"markdown","metadata":{"id":"900dqb9wKoXJ","colab_type":"text"},"source":["# Convolutional neural networks #"]},{"cell_type":"markdown","metadata":{"id":"Mql7DZkD0cDS","colab_type":"text"},"source":["### Reconsidering our image recognition approach so far ###\n","\n","Let us for a moment reconsider our 2-layer perceptron from a a few weeks ago:\n","\n","$$ \\mathcal{D} = \\{(x_1, y_1), \\ldots, (x_n, y_n)\\} $$\n","\n","$$ x_i \\in \\mathbb{R}^{28 \\cdot 28} $$\n","\n","$$ y_i \\in \\{0, 1\\} $$\n","\n","$$ W_1 \\in \\mathbb{R}^{h \\times 28 \\cdot 28} $$\n","\n","$$ b_1 \\in \\mathbb{R}^{h} $$\n","\n","$$ W_2 \\in \\mathbb{R}^{1 \\times h} $$\n","\n","$$ b_2 \\in \\mathbb{R} $$\n","\n","$$ f(x) = \\sigma(W_2 * \\sigma(W_1 x + b_1) + b_2) $$\n","\n","$$ L(x, y) = P(y=\\hat{y}|x) $$\n","\n","How does each weight in $W_1$ relate to each input pixel? How does each weight in $W_2$ relate to each input pixel?"]},{"cell_type":"markdown","metadata":{"id":"4F4GiLdQ-XL6","colab_type":"text"},"source":["\n","## Invariance ###\n","\n","![](https://i.stack.imgur.com/iY5n5.png)\n","\n","[Image source](https://i.stack.imgur.com/iY5n5.png)\n","\n","As humans, we can clearly see that each of these images are of the same object. Thus, it is clearly desireable that the same would hold for a machine learning algorithm. Consider the multi-layer perceptron we just discussed, how would it react to say translating the image? Could you conceive of a way to make it robust to translation by modifying $\\mathcal{D}$?\n","\n","![](https://www.learnopencv.com/wp-content/uploads/2017/11/failure-mlp-mnist.jpg)\n","\n","[Image source](https://www.learnopencv.com/wp-content/uploads/2017/11/failure-mlp-mnist.jpg)\n","\n","Note here how the classification decision changes depending on the location of the digit inside the image, double-plus ungood indeed."]},{"cell_type":"markdown","metadata":{"id":"Z5lXeuH7-Y2w","colab_type":"text"},"source":["## Scale-Invariant Feature Transform (SIFT) ##\n","\n","Pre-deep learning approaches to address this.\n","\n","![](https://upload.wikimedia.org/wikipedia/commons/4/44/Sift_keypoints_filtering.jpg)\n","\n","[Image source](https://en.wikipedia.org/wiki/File:Sift_keypoints_filtering.jpg)\n","\n","Plenty of competitors published throughout the 00s:\n","\n","* Speeded Up Robust Features (SURF)\n","* Gradient Location and Orientation Histogram\n","* Etc.\n","\n","One would apply these feature extraction methods to an input image, then feed the resulting features into a linear classifier or SVM. Does this sound familiar? What is a disadvantage with this approach if we put our deep learning glasses on?"]},{"cell_type":"markdown","metadata":{"id":"0Em6g80Bzu-o","colab_type":"text"},"source":["## General architecture ##\n","\n","![](https://cdn-images-1.medium.com/max/2000/1*1TI1aGBZ4dybR6__DI9dzA.png)\n","\n","[Image source](https://cdn-images-1.medium.com/max/2000/1*1TI1aGBZ4dybR6__DI9dzA.png)\n","\n","LeNet-5 by LeCun et al. (1998), the archetypical convolutional neural network."]},{"cell_type":"markdown","metadata":{"id":"D8EZSgtX67rf","colab_type":"text"},"source":["### Filters or feature detectors ###\n","\n","![](https://www.jeremyjordan.me/content/images/2017/07/Screen-Shot-2017-07-26-at-5.15.35-PM.png)\n","\n","[Image source](https://www.jeremyjordan.me/content/images/2017/07/Screen-Shot-2017-07-26-at-5.15.35-PM.png)\n","\n","![](https://www.jeremyjordan.me/content/images/2017/08/Screen-Shot-2017-08-23-at-5.05.59-PM.png)\n","\n","[Image source](https://www.jeremyjordan.me/content/images/2017/08/Screen-Shot-2017-08-23-at-5.05.59-PM.png)\n","\n","![](https://www.jeremyjordan.me/content/images/2017/07/Screen-Shot-2017-07-26-at-6.13.41-PM.png)\n","\n","[Image source](https://www.jeremyjordan.me/content/images/2017/07/Screen-Shot-2017-07-26-at-6.13.41-PM.png)\n","\n","![](https://www.jeremyjordan.me/content/images/2017/07/no_padding_no_strides.gif)\n","\n","[Image source](https://github.com/vdumoulin/conv_arithmetic)\n","\n","![](https://www.jeremyjordan.me/content/images/2017/07/same_padding_no_strides.gif)\n","\n","[Image source](https://github.com/vdumoulin/conv_arithmetic)\n","\n","Note the padding to allow for the filter to operate near the edges of the image."]},{"cell_type":"markdown","metadata":{"id":"lJLSoAxc7ENd","colab_type":"text"},"source":["## Pooling or “subsampling” ##\n","\n","![](http://www.embedded-vision.com/sites/default/files/technical-articles/CadenceCNN/Figure7.jpg)\n","\n","[Image source](http://www.embedded-vision.com/sites/default/files/technical-articles/CadenceCNN/Figure7.jpg)\n","\n","What does this achieve conceptually? What would happen if we only performed one round of convolution?"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"23lie7xtZpoz"},"source":["## Classification layer ##\n","\n","![](https://cdn-images-1.medium.com/max/2000/1*1TI1aGBZ4dybR6__DI9dzA.png)\n","\n","[Image source](https://cdn-images-1.medium.com/max/2000/1*1TI1aGBZ4dybR6__DI9dzA.png)\n","\n","What about the last layer then? It is simply a good old multi-layer perceptron."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"betCSDXpZpyb"},"source":["## A topological view ##\n","\n","![](https://1.bp.blogspot.com/-hoMkm-o_Lis/V0j1PegTSRI/AAAAAAAAEGE/knUuQfffTbggINk49msVYwM70D2qL4sKgCLcB/s1600/topological-visualisation-convolutional-neural-network.jpg)\n","\n","[Image source](https://1.bp.blogspot.com/-hoMkm-o_Lis/V0j1PegTSRI/AAAAAAAAEGE/knUuQfffTbggINk49msVYwM70D2qL4sKgCLcB/s1600/topological-visualisation-convolutional-neural-network.jpg)\n","\n","I found this recently and I think it illustrates very well how one can look at the filters operating on the input image."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dpabwukXZp-q"},"source":["## “So what does it actually learn“ ##\n","\n","We are used to this question at this point, a whole lot it turns out. How would you relate this to SIFT and friends?\n","\n","![](http://i.stack.imgur.com/Hl2H6.png)\n","\n","[Image source](http://i.stack.imgur.com/Hl2H6.png)\n","\n","Composition of features, edges into pieces, and into items.\n","\n","![](https://elix-tech.github.io/images/2016/art/cnn.png)\n","\n","![](https://cdn-images-1.medium.com/max/1200/1*HHUeLYdJosHkerJUNKWGrg.png)\n","\n","![](http://dataguild.org/wp-content/uploads/2017/04/science-and-art-via-cnn-09.png)\n","\n","I finally found a good illustration highlighting the inner workings of the method, note the gradient flows and how different layers are tied together. It is also worth noting that the convolutional network uses the same weights for all three images and that is is pre-trained for image classification."]}]}